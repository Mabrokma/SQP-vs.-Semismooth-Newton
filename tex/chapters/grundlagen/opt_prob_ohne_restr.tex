Wir betrachten nun das unrestringierte Optimierungsproblem
\begin{equation}
  \min_{x \in \R^n} f(x). \label{eq:uop}
\end{equation}

Wir nehmen hier der Einfachheit halber an, dass der Definitionsbereich $D$
gleich $\R^n$ sei.

\begin{theorem}
\emph{(Notwendige Bedingung erster Ordnung)}
Seien $\xopt$ eine lokale Lösung des Problems~(\ref{eq:uop}) und $f$ einmal stetig
differenzierbar in einer Umgebung von $\xopt$, dann gilt
\begin{equation}
  \nabla f(\xopt) = 0 \label{eq:grad_zero}
\end{equation}
\end{theorem}

Diese Bedingung gilt aber nicht nur für lokales Minimum sondern auch für lokales
Maximum von $f$.

\begin{definition}
\emph{(Stationärer Punkt)}
$f$ sei in $\xopt$ differenzierbar. $\xopt$ heißt ein stationärer Punkt von $f$,
wenn $\xopt$ die notwendige Bedingung~(\ref{eq:grad_zero}) erfüllt.
\end{definition}

Viele Optimierungsverfahren suchen in der Regel nach einem stationärem Punkt
von~$f$.
Aber ein stationärer Punkt muss nicht ein globales oder lokales Minimum sein.

\begin{theorem}
\emph{(Notwendige Bedingung zweiter Ordnung)}
Seien $\xopt$ eine lokale Lösung des Problems~(\ref{eq:uop}) und $f$ zweimal stetig
differenzierbar in einer Umgebung von $\xopt$, dann gilt~(\ref{eq:grad_zero}) und
\begin{equation}
  x^T f''(\xopt) x \geq 0 \qquad \forall x \in \R^n,
\end{equation}
$f''(\xopt)$ ist also positiv semidefinit.
\end{theorem}

Durch diese notwendige Bedingung können wir zwischen einem lokalen Minimum und
Maximum unterscheiden.

\begin{theorem}
\emph{(Hinreichende Bedingung zweiter Ordnung)}
Sei $f$ zweimal stetig differenzierbar in einer Umgebung von $\xopt$.
Die notwendige Bedingung~(\ref{eq:grad_zero}) sei erfüllt und $f''(\xopt)$
sei positiv definit, d.h.
\begin{equation}
  x^T f''(\xopt) x > 0 \qquad \forall x \in \R^n.
\end{equation}
Dann ist $\xopt$ eine strikte Lösung des Problems~(\ref{eq:uop}).
\end{theorem}

Diese hinreichende Bedingung benutzt man in der Regel erst dann, wenn man einen
stationären Punkt findet.

\begin{definition}
\emph{(Abstiegsrichtung)}
Sei $f:\R^n \rightarrow \R$ differenzierbar in $x$. Ein Vektor
$d \in \R^n\backslash\{0\}$ heißt Abstiegsrichtung von~$f$ in~$x$, wenn
\begin{equation}
  \nabla f(x)^T d < 0
\end{equation}
gilt.
\end{definition}

Ist $\nabla f(x) \neq 0$, dann ist beispielsweise $d = - \nabla f(x)$ eine
Abstiegsrichtung von $f$ in $x$.

\begin{theorem}
Seien $f:\R^n \rightarrow \R$ differenzierbar in $x$ und $d$ eine
Abstiegsrichtung von $f$ in $x$. Dann gibt es ein $\hat{\sigma} > 0$ mit
\begin{equation}
  f( x + \sigma d) < f(x) \qquad \forall \sigma \in ]0, \hat{\sigma}[.
\end{equation}
\end{theorem}

Die meisten Optimierungsverfahren sind iterativ. Sie fangen mit einem
Anfangspunkt $x^0$ an und versuchen dann weitere Punkte ($x^1, x^2, \ldots , x^k
, \ldots$) zu finden, die besser als die vorherige sind.
Viele iterative Verfahren zur Bestimmung eine lokale Lösung sind häufig
Abstiegsverfahren. In der $k$-ten Iteration bestimmen sie zu einem Punkt $x^k$
eine Abstiegsrichtung $d^k$ und eine Schrittweite $\sigma_k$, sodass für
$x^{k+1} := x^k + \sigma_k d^k$
\begin{equation}
  f(x^{k+1}) < f(x^k)
\end{equation}
gilt.

Das Gradientenverfahren ist ein einfaches Abstiegsverfahren,
welches die negative Gradienten als Abstiegsrichtungen verwendet.

\begin{algorithm}
\emph{(Gradientenverfahren)}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und ein Abbruchkriterium $\epsilon > 0$.
        Setze $k := 0$.
  \item Ist $||\nabla f(x^k)|| < \epsilon$ \label{list:stop_criteria_GV}
        $\Rightarrow$ STOP.
  \item Setze $d^k := - \nabla f(x^k)$.
  \item Bestimme $\sigma_k$ so, dass
        \begin{equation}
          f(x^k + \sigma_k d^k) < f(x^k + \sigma d^k)
            \qquad \forall \sigma \geq 0.
        \end{equation}
  \item Setze $x^{k+1} := x^k + \sigma_k d^k$ und $k := k+1$ $\Rightarrow$
        Gehe zu Schritt~\ref{list:stop_criteria_GV}.
\end{enumerate}
\end{algorithm}

Eine andere Möglichkeit ist, dass man das Newton-Verfahren verwendet,
um die Lösung der Gleichung~\eqref{eq:grad_zero} zu finden.

\begin{algorithm}
\emph{(Newton-Verfahren)}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und ein Abbruchkriterium $\epsilon > 0$.
        Setze $k := 0$.
  \item Ist $||\nabla f(x^k)|| < \epsilon$ \label{list:stop_criteria_NV}
        $\Rightarrow$ STOP.
  \item Berechne die Lösung $d$ des linearen Gleichungssystems
        \begin{equation}
          f''(x^k) d = - \nabla f(x^k).
        \end{equation}
        Setze $d^k := d$.
  \item Setze $x^{k+1} := x^k + d^k$ und $k := k+1$ $\Rightarrow$
        Gehe zu Schritt~\ref{list:stop_criteria_NV}.
\end{enumerate}
\end{algorithm}

Man kann auch noch eine Scrittweitensteuerung durchführen, dann bekommt man ein
Abstiegsverfahren, welches man als das gedämpfte Newton-Verfahren bezeichnet.
Man ersetzt dazu den Schritt 4 in dem Newton-Verfahren mit den Schritten 4 und 5
in dem Gradientenverfahren.
