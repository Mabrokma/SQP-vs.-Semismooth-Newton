Wir beginnen nun zuerst mit Optimierungsproblemen ohne Restriktionen
und stellen die notwendigen und hinreichenden Optimalitätsbedingungen bereit.
Zwei numerische Verfahren hierfür werden auch vorgestellt.

\begin{definition}
\emph{(Unrestringierte Optimierungsprobleme)}
\begin{equation}
  \min_{x \in \R^n} f(x). \tag{PU} \label{prob:opt_prob_unrestr}
\end{equation}
Wir nehmen hier der Einfachheit halber an, dass der Definitionsbereich
$D$ gleich $\R^n$ sei.
\end{definition}

\begin{example}\label{example:lineare_regression}
\emph{(Lineare Regression, vgl. Beispiel 1.1.6 in \cite[S.~4~f.]{alt})}\\
Ein praktisches Beispiel ist
die Aufgabe der linearen Regression.
Gegeben seien m Messwerte
$(\xi_1,\eta_1),\ldots,(\xi_m,\eta_m)$.
Gesucht ist eine Gerade
\begin{equation}
  \eta(\xi) := x_1 \xi + x_2,
\end{equation}
die \textss{optimal} zu den Messwerten passt.
D.\,h., der Parameter $x = (x_1,x_2)^T \in \R^2$
soll so bestimmt werden, dass die Summe der Fehlerquadrate
in den Messpunkten minimiert wird.
Somit ist ein unrestringiertes Optimierungsproblem
\begin{equation}
  \min_{x \in \R^2}\ 
  f(x) := \sum_{i=1}^{m} (\eta(\xi_i) - \eta_i)^2
        = \sum_{i=1}^{m} (x_1 \xi_i + x_2 - \eta_i)^2
\end{equation}
zu lösen.
\end{example}

\begin{example}\label{example:nichtlineare_regression}
\emph{(Nichtlineare Regression, vgl. Abschnitt 2.3.2 in \cite[S.~30~f.]{alt})}\\
Neben linearen Regressionsaufgaben sind auch oft
nichtlineare Regressionsaufgaben zu lösen.
Gesucht ist der funktionale Zusammenhang $\eta(\xi)$
zwischen den $\xi$- und den $\eta$-Werten,
beispielsweise
\begin{equation}\label{eq:nichtlin_regres_quad_zusammenhang}
  \eta(\xi) := x_1 (\xi -x_2)^2 + x_3
\end{equation}
oder
\begin{equation}\label{eq:nichtlin_regres_exp_zusammenhang}
  \eta(\xi) := x_1 e^{\xi x_2}.
\end{equation}
Dabei ist $x = (x_1,\ldots,x_n)^T \in \R^n$ ein Parametervektor,
der \textss{optimal}
bestimmt werden soll.
\end{example}

\begin{theorem}
\label{satz:notw_bed_fuer_unrestr_prob}
\emph{(Notwendige Bedingung erster Ordnung, vgl. Satz 3.1.2 in
\cite[S.~42]{alt})}\\
Sei $\xopt$ eine lokale Lösung des Problems~(\ref{prob:opt_prob_unrestr}) und
sei $f$ einmal stetig differenzierbar in einer Umgebung von $\xopt$,
dann gilt
\begin{equation}
  \nabla f(\xopt) = 0. \label{eq:grad_zero}
\end{equation}
\end{theorem}

Die Bedingung~\eqref{eq:grad_zero} gilt aber nicht nur für lokale Minima
sondern auch für lokale Maxima von~$f$.

\begin{definition}
\emph{(Stationärer Punkt, vgl. Definition 3.1.4 in \cite[S.~42]{alt})}\\
Die Funktion $f$ sei in $\xopt$ differenzierbar. Der Punkt $\xopt$ heißt
stationärer Punkt von $f$, wenn $\xopt$ die notwendige Bedingung~(\ref{eq:grad_zero})
erfüllt.
\end{definition}

Viele Optimierungsverfahren suchen in der Regel nach einem stationären Punkt
von~$f$.
Aber ein stationärer Punkt muss kein globales oder lokales Minimum sein.
Durch folgende notwendige Bedingung kann man zwischen einem lokalen Minimum und
einem lokalen Maximum unterscheiden.

\begin{theorem}
\emph{(Notwendige Bedingung zweiter Ordnung, vgl. Satz 3.1.6 in
\cite[S.~43]{alt})}\\
Sei $\xopt$ eine lokale Lösung des Problems~(\ref{prob:opt_prob_unrestr})
und sei $f$ zweimal stetig differenzierbar in einer Umgebung von $\xopt$,
dann gilt~(\ref{eq:grad_zero}) und
\begin{equation}
  x^T f''(\xopt) x \geq 0 \qquad \forall x \in \R^n.
\end{equation}
$f''(\xopt)$ ist also positiv semidefinit.
\end{theorem}

\begin{theorem}
\emph{(Hinreichende Bedingung zweiter Ordnung, vgl. Satz 3.1.11 in
\cite[S.~44]{alt})}\\
Sei $f$ zweimal stetig differenzierbar in einer Umgebung von $\xopt$.
Die notwendige Bedingung~(\ref{eq:grad_zero}) sei erfüllt und $f''(\xopt)$
sei positiv definit, d.\,h.
\begin{equation}
  x^T f''(\xopt) x > 0 \qquad \forall x \in \R^n.
\end{equation}
Dann ist $\xopt$ eine strikte Lösung des Problems~(\ref{prob:opt_prob_unrestr}).
\end{theorem}

Diese hinreichende Bedingung benutzt man in der Regel erst dann, wenn man einen
stationären Punkt findet.

Eine wichtige Grundlage für einige Verfahren ist
die Definition der Abstiegsrichtung.

\begin{definition}
\label{def:abstiegsrichtung}
\emph{(Abstiegsrichtung, vgl. Definition 4.1.2 in \cite[S.~68]{alt})}\\
Die Funktion $f$ sei differenzierbar in $x$. Ein Vektor
$d \in \R^n\backslash\{0\}$ heißt Abstiegsrichtung von~$f$ in~$x$, wenn
\begin{equation}
  \nabla f(x)^T d < 0
\end{equation}
gilt.
\end{definition}

Sei $x \in \R^n$ mit $\nabla f(x) \neq 0$, dann ist beispielsweise $d = - \nabla
f(x)$ eine Abstiegsrichtung von~$f$ in~$x$.

\begin{theorem}
\label{satz:existenz_von_schrittweite}
\emph{(Vgl. Lemma 4.1.1 in \cite[S.~68]{alt})}\\
Seien $x \in \R^n$, $f$ differenzierbar in $x$ und $d$
eine Abstiegsrichtung von $f$ in $x$. Dann gibt es ein $\hat{\sigma} > 0$ mit
\begin{equation}
  f( x + \sigma d) < f(x) \qquad \forall \sigma \in \ ]0, \hat{\sigma}[.
\end{equation}
\end{theorem}

Die meisten Optimierungsverfahren sind iterativ. Sie fangen also mit einem
Anfangspunkt $x^0$ an und versuchen dann weitere Punkte ($x^1, x^2, \ldots , x^k
, \ldots$) zu finden, die besser als die vorherigen sind.
Viele iterative Verfahren zur Bestimmung einer lokalen Lösung sind häufig
Abstiegsverfahren. In der $k$-ten Iteration bestimmen sie zu einem Punkt~$x^k$
eine Abstiegsrichtung~$d^k$ und eine Schrittweite $\sigma_k$ so, dass für
$x^{k+1} := x^k + \sigma_k d^k$
\begin{equation}
  f(x^{k+1}) < f(x^k)
\end{equation}
gilt.

\subsection{Gradientenverfahren}

Das Gradientenverfahren ist ein einfaches Abstiegsverfahren,
welches die negativen Gradienten als Abstiegsrichtungen verwendet.

\begin{algorithm}
\emph{(Gradientenverfahren, vgl. Verfahren 4.2.39 in \cite[S.~98]{alt})}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und setze $k := 0$.
  \item Setze $d^k := - \nabla f(x^k)$. \label{list:compute_d_in_grad_verf}
  \item Ist $d^k = 0$ $\Rightarrow$ STOP. \label{list:stop_criteria_grad_verf}
  \item Bestimme Schrittweite $\sigma_k$ so, dass
        \begin{equation}
          f(x^k + \sigma_k d^k) < f(x^k + \sigma d^k)
            \qquad \forall \sigma \geq 0.
        \end{equation}
  \item Setze $x^{k+1} := x^k + \sigma_k d^k$ und $k := k+1$. $\Rightarrow$
        Gehe zu Schritt~\ref{list:compute_d_in_grad_verf}.
\end{enumerate}
\end{algorithm}

Es ist zu beachten, dass die Abbruchbedingung in
Schritt~\ref{list:stop_criteria_grad_verf}
nur theoretisch zu verstehen ist.
Praktisch gibt man eine Abbruchschranke $\varepsilon > 0$ vor
und führt beispielsweise den Test
\begin{equation}
  \|d^k\| < \varepsilon
\end{equation}
durch.

Zur Bestimmung der Schrittweite $\sigma_k$ kann man das
Schrittweitenverfahren von Armijo oder das Schrittweitenverfahren von
Wolfe-Powell verwenden (vgl. Abschnitt 4.2.7 in \cite[S.~90~ff.]{alt}).

\subsection{Newton-Verfahren} \label{sec:newton_verfahren}

Ein bekanntes Verfahren der numerischen Mathematik, um eine nichtlineare
Gleichung zu lösen, ist das Newton-Verfahren.
Man berechnet mit dem Newton-Verfahren eine Nullstelle
von einer gegebenen Abbildung $F:\R^n \rightarrow \R^n$,
d.\,h. eine Lösung $\xopt \in \R^n$ der nichtlinearen Gleichung $F(x) = 0$.
Für die unrestringierten Optimierungsprobleme kann das Newton-Verfahren
angewendet werden, um die Lösung der nichtlinearen
Gleichung~\eqref{eq:grad_zero},
$\nabla f(x) = 0$, zu finden.
Es wird dabei vorausgesetzt,
dass die Funktion $f$ zweimal differenzierbar ist.

\begin{algorithm}
\emph{(Newton-Verfahren, vgl. Verfahren 4.3.1 in \cite[S.~107]{alt})}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und setze $k := 0$.
  \item Ist $\nabla f(x^k) = 0$ \label{list:stop_criteria_newt_verf}
        $\Rightarrow$ STOP.
  \item Berechne die Lösung $d$ des linearen Gleichungssystems
        \begin{equation}
          f''(x^k) d = - \nabla f(x^k).
        \end{equation}
        Setze $d^k := d$.
  \item Setze $x^{k+1} := x^k + d^k$ und $k := k+1$ $\Rightarrow$
        Gehe zu Schritt~\ref{list:stop_criteria_newt_verf}.
\end{enumerate}
\end{algorithm}

Der Punkt $x^{k+1}$ in jedem Iterationsschritt ist eigentlich die Lösung des
Minimierungsproblems, welches durch die quadratische Approximation von $f$ in Punkt $x^k$ definiert ist.
In der Umgebung von $x^k$ kann die Funktion $f$ wie folgt approximiert werden:
\begin{equation}
  f(x) \approx f(x^k) + \nabla f(x^k)^T (x-x^k)
                 + \frac{1}{2} (x-x^k)^T f''(x^k) (x-x^k).
\end{equation}
Die Ableitung der rechten Seite ist
\begin{equation}
  \nabla f(x^k) + f''(x^k) x - f''(x^k) x^k.
\end{equation}
Setzt man diese gleich null, dann bekommt man
\begin{align}
  f''(x^k) (x-x^k) & = - \nabla f(x^k) \\
            x-x^k  & = - [f''(x^k)]^{-1} \nabla f(x^k) \\
            x      & = x^k \underbrace{- [f''(x^k)]^{-1} \nabla f(x^k)}_{d}.
\end{align}
Das ist genau unser Punkt $x^{k+1}$.
D.\,h., es wird in jedem Iterationsschritt eigentlich das Problem
\begin{equation}
  \min_{x \in \R^n}\ f(x^k) + \nabla f(x^k)^T (x-x^k)
                 + \frac{1}{2} (x-x^k)^T f''(x^k) (x-x^k)
\end{equation}
gelöst, wobei die Konstante $f(x^k)$ weggelassen werden kann.

Es ist später zu sehen, dass das SQP-Verfahren diese Idee auch
gebrauchen wird.

Eine Schrittweitensteuerung wie bei dem Gradientenverfahren kann auch
durchgeführt werden, d.\,h., man bestimmt ein $\sigma_k \in \R$ und definiert
$x^{k+1} := x^k + \sigma_k d^k$.
Dann bekommt man ein Abstiegsverfahren,
welches als das gedämpfte Newton-Verfahren bezeichnet wird
(vgl. Abschnitt 4.3.2 in \cite[S.~111~ff.]{alt}).