Wir betrachten nun zuerst unrestringierte Optimierungsprobleme.

\begin{definition}
\emph{(Unrestringierte Optimierungsprobleme)}
\begin{equation}
  \min_{x \in \R^n} f(x). \label{eq:uop}
\end{equation}
\end{definition}
Wir nehmen hier der Einfachheit halber an, dass der Definitionsbereich
$D$ gleich $\R^n$ sei.

\begin{theorem}
\emph{(Notwendige Bedingung erster Ordnung)}
Sei $\xopt$ eine lokale Lösung des Problems~(\ref{eq:uop}) und
sei $f$ einmal stetig differenzierbar in einer Umgebung von $\xopt$,
dann gilt
\begin{equation}
  \nabla f(\xopt) = 0 \label{eq:grad_zero}
\end{equation}
\end{theorem}

Diese Bedingung gilt aber nicht nur für lokales Minimum sondern auch für lokales
Maximum von $f$.

\begin{definition}
\emph{(Stationärer Punkt)}
$f$ sei in $\xopt$ differenzierbar. $\xopt$ heißt ein stationärer Punkt von $f$,
wenn $\xopt$ die notwendige Bedingung~(\ref{eq:grad_zero}) erfüllt.
\end{definition}

Viele Optimierungsverfahren suchen in der Regel nach einem stationärem Punkt
von~$f$.
Aber ein stationärer Punkt muss nicht ein globales oder lokales Minimum sein.

\begin{theorem}
\emph{(Notwendige Bedingung zweiter Ordnung)}
Sei $\xopt$ eine lokale Lösung des Problems~(\ref{eq:uop})
und sei $f$ zweimal stetig differenzierbar in einer Umgebung von $\xopt$,
dann gilt~(\ref{eq:grad_zero}) und
\begin{equation}
  x^T f''(\xopt) x \geq 0 \qquad \forall x \in \R^n.
\end{equation}
$f''(\xopt)$ ist also positiv semidefinit.
\end{theorem}

Durch diese notwendige Bedingung kann man zwischen einem lokalen Minimum und
einem lokalen Maximum unterscheiden.

\begin{theorem}
\emph{(Hinreichende Bedingung zweiter Ordnung)}
Sei $f$ zweimal stetig differenzierbar in einer Umgebung von $\xopt$.
Die notwendige Bedingung~(\ref{eq:grad_zero}) sei erfüllt und $f''(\xopt)$
sei positiv definit, d.\,h.
\begin{equation}
  x^T f''(\xopt) x > 0 \qquad \forall x \in \R^n.
\end{equation}
Dann ist $\xopt$ eine strikte Lösung des Problems~(\ref{eq:uop}).
\end{theorem}

Diese hinreichende Bedingung benutzt man in der Regel erst dann, wenn man einen
stationären Punkt findet.

Eine wichtige Grundlage für einige Verfahren ist
die Definition von der Abstiegsrichtung.

\begin{definition}
\emph{(Abstiegsrichtung)}
Sei $f:\R^n \rightarrow \R$ differenzierbar in $x$. Ein Vektor
$d \in \R^n\backslash\{0\}$ heißt Abstiegsrichtung von~$f$ in~$x$, wenn
\begin{equation}
  \nabla f(x)^T d < 0
\end{equation}
gilt.
\end{definition}

Sei $x \in \R^n$ mit $\nabla f(x) \neq 0$, dann ist beispielsweise $d = - \nabla
f(x)$ eine Abstiegsrichtung von $f$ in $x$.

\begin{theorem}
Seien $x \in \R^n$, $f:\R^n \rightarrow \R$ differenzierbar in $x$ und $d$
eine Abstiegsrichtung von $f$ in $x$. Dann gibt es ein $\hat{\sigma} > 0$ mit
\begin{equation}
  f( x + \sigma d) < f(x) \qquad \forall \sigma \in \ ]0, \hat{\sigma}[.
\end{equation}
\end{theorem}

Die meisten Optimierungsverfahren sind iterativ. Sie fangen also mit einem
Anfangspunkt $x^0$ an und versuchen dann weitere Punkte ($x^1, x^2, \ldots , x^k
, \ldots$) zu finden, die besser als die vorherige sind.
Viele iterative Verfahren zur Bestimmung eine lokale Lösung sind häufig
Abstiegsverfahren. In der $k$-ten Iteration bestimmen sie zu einem Punkt $x^k$
eine Abstiegsrichtung $d^k$ und eine Schrittweite $\sigma_k$, sodass für
$x^{k+1} := x^k + \sigma_k d^k$
\begin{equation}
  f(x^{k+1}) < f(x^k)
\end{equation}
gilt.

\subsection{Gradientenverfahren}

Das Gradientenverfahren ist ein einfaches Abstiegsverfahren,
welches die negative Gradienten als Abstiegsrichtungen verwendet.

\begin{algorithm}
\emph{(Gradientenverfahren)}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und ein Abbruchkriterium $\epsilon > 0$.
        Setze $k := 0$.
  \item Ist $||\nabla f(x^k)|| < \epsilon$ \label{list:stop_criteria_grad_verf}
        $\Rightarrow$ STOP.
  \item Setze $d^k := - \nabla f(x^k)$.
  \item Bestimme $\sigma_k$ so, dass
        \begin{equation}
          f(x^k + \sigma_k d^k) < f(x^k + \sigma d^k)
            \qquad \forall \sigma \geq 0.
        \end{equation}
  \item Setze $x^{k+1} := x^k + \sigma_k d^k$ und $k := k+1$ $\Rightarrow$
        Gehe zu Schritt~\ref{list:stop_criteria_grad_verf}.
\end{enumerate}
\end{algorithm}

Um die Schrittweite $\sigma_k$ zu bestimmen, kann man das Armijo-Verfahren
oder das Powell-Verfahren verwenden. %TODO Siehe ..

\subsection{Newton-Verfahren} \label{sec:newton_verfahren}

Ein bekanntes Verfahren, um nichtlineare Gleichungssysteme zu lösen,
ist das Newton-Verfahren.
Für unsere unrestringierte Optimierungsprobleme können wir das Newton-Verfahren
verwenden, um die Lösung des nichtlinearen
Gleichungssystems~\eqref{eq:grad_zero},
also $\nabla f(x) = 0$, zu finden.
Man muss dabei voraussetzen, dass die Funktion $f$ zweimal differenzierbar
sei.

\begin{algorithm}
\emph{(Newton-Verfahren)}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und ein Abbruchkriterium $\epsilon > 0$.
        Setze $k := 0$.
  \item Ist $||\nabla f(x^k)|| < \epsilon$ \label{list:stop_criteria_newt_verf}
        $\Rightarrow$ STOP.
  \item Berechne die Lösung $d$ des linearen Gleichungssystems
        \begin{equation}
          f''(x^k) d = - \nabla f(x^k).
        \end{equation}
        Setze $d^k := d$.
  \item Setze $x^{k+1} := x^k + d^k$ und $k := k+1$ $\Rightarrow$
        Gehe zu Schritt~\ref{list:stop_criteria_newt_verf}.
\end{enumerate}
\end{algorithm}

Der Punkt $x^{k+1}$ in jedem Iterationschritt ist eigentlich die Lösung des
Minimierungsproblems, welches durch die quadratische Approximation von $f$ in Punkt $x^k$ definiert ist.
In der Umgebung von $x^k$ können wir die Funktion $f$ wie folgt approximieren:
\begin{equation}
  f(x) \approx f(x^k) + \nabla f(x^k)^T (x-x^k)
                 + \frac{1}{2} (x-x^k)^T f''(x^k) (x-x^k).
\end{equation}
Die Ableitung der rechten Seite ist
\begin{equation}
  f''(x^k) x + \nabla f(x^k) - f''(x^k) x^k.
\end{equation}
Setzen wir diese gleich null, dann bekommen wir
\begin{align}
  f''(x^k) (x-x^k) & = - \nabla f(x^k) \\
            x-x^k  & = - [f''(x^k)]^{-1} \nabla f(x^k) \\
            x      & = x^k - [f''(x^k)]^{-1} \nabla f(x^k).
\end{align} %TODO d in der Gleichung zeigen
Das ist genau unser Punkt $x^{k+1}$.
D.\,h., wir lösen in jedem Iterationschritt eigentlich das Problem
\begin{equation}
  \min_{x \in \R^n}\ f(x^k) + \nabla f(x^k)^T (x-x^k)
                 + \frac{1}{2} (x-x^k)^T f''(x^k) (x-x^k),
\end{equation}
wobei die Konstante $f(x^k)$ weggelassen werden kann.

Wir werden später sehen, dass das SQP-Verfahren diese Idee auch
gebrauchen wird.
%TODO unklar..
Man kann außerdem auch Scrittweitensteuerung durchführen, dann bekommt
man ein Abstiegsverfahren, welches man als das gedämpfte Newton-Verfahren bezeichnet.

% TODO Quasi-Newton-Verfahren bzw. BFGS-Verfahren erwähnen.

% TODO Das Konvergenzverhalten der Verfahren erwähnen?
