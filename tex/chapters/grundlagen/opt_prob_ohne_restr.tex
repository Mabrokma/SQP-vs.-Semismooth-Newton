Wir beginnen nun zuerst mit Optimierungsproblemen ohne Restriktionen
und stellen die notwendige und hinreichende Optimalitätsbedingungen bereit.
Wir werden auch zwei numerische Verfahren hierfür vorstellen.

\begin{definition}
\emph{(Unrestringierte Optimierungsprobleme)}
\begin{equation}
  \min_{x \in \R^n} f(x) \tag{PU} \label{eq:uop}
\end{equation}
\end{definition}
Wir nehmen hier der Einfachheit halber an, dass der Definitionsbereich
$D$ gleich $\R^n$ sei.

\begin{theorem}
\emph{(Notwendige Bedingung erster Ordnung, vgl. Satz 3.1.2 in
\cite[S.~42]{alt})}\\
Sei $\xopt$ eine lokale Lösung des Problems~(\ref{eq:uop}) und
sei $f$ einmal stetig differenzierbar in einer Umgebung von $\xopt$,
dann gilt
\begin{equation}
  \nabla f(\xopt) = 0. \label{eq:grad_zero}
\end{equation}
\end{theorem}

Die Bedingung~\eqref{eq:grad_zero} gilt aber nicht nur für lokales Minimum
sondern auch für lokales Maximum von~$f$.

\begin{definition}
\emph{(Stationärer Punkt, vgl. Definition 3.1.4 in \cite[S.~42]{alt})}\\
Die Funktion $f$ sei in $\xopt$ differenzierbar. Der Punkt $\xopt$ heißt ein
stationärer Punkt von $f$, wenn $\xopt$ die notwendige Bedingung~(\ref{eq:grad_zero})
erfüllt.
\end{definition}

Viele Optimierungsverfahren suchen in der Regel nach einem stationärem Punkt
von~$f$.
Aber ein stationärer Punkt muss nicht ein globales oder lokales Minimum sein.
Durch folgende notwendige Bedingung kann man zwischen einem lokalen Minimum und
einem lokalen Maximum unterscheiden.

\begin{theorem}
\emph{(Notwendige Bedingung zweiter Ordnung, vgl. Satz 3.1.6 in
\cite[S.~43]{alt})}\\
Sei $\xopt$ eine lokale Lösung des Problems~(\ref{eq:uop})
und sei $f$ zweimal stetig differenzierbar in einer Umgebung von $\xopt$,
dann gilt~(\ref{eq:grad_zero}) und
\begin{equation}
  x^T f''(\xopt) x \geq 0 \qquad \forall x \in \R^n.
\end{equation}
$f''(\xopt)$ ist also positiv semidefinit.
\end{theorem}

\begin{theorem}
\emph{(Hinreichende Bedingung zweiter Ordnung, vgl. Satz 3.1.11 in
\cite[S.~44]{alt})}\\
Sei $f$ zweimal stetig differenzierbar in einer Umgebung von $\xopt$.
Die notwendige Bedingung~(\ref{eq:grad_zero}) sei erfüllt und $f''(\xopt)$
sei positiv definit, d.\,h.
\begin{equation}
  x^T f''(\xopt) x > 0 \qquad \forall x \in \R^n.
\end{equation}
Dann ist $\xopt$ eine strikte Lösung des Problems~(\ref{eq:uop}).
\end{theorem}

Diese hinreichende Bedingung benutzt man in der Regel erst dann, wenn man einen
stationären Punkt findet.

Eine wichtige Grundlage für einige Verfahren ist
die Definition der Abstiegsrichtung.

\begin{definition}
\emph{(Abstiegsrichtung, vgl. Definition 4.1.2 in \cite[S.~68]{alt})}\\
Die Funktion $f:\R^n \rightarrow \R$ sei differenzierbar in $x$. Ein Vektor
$d \in \R^n\backslash\{0\}$ heißt Abstiegsrichtung von~$f$ in~$x$, wenn
\begin{equation}
  \nabla f(x)^T d < 0
\end{equation}
gilt.
\end{definition}

Sei $x \in \R^n$ mit $\nabla f(x) \neq 0$, dann ist beispielsweise $d = - \nabla
f(x)$ eine Abstiegsrichtung von~$f$ in~$x$.

\begin{theorem}
\emph{(vgl. Lemma 4.1.1 in \cite[S.~68]{alt})}\\
Seien $x \in \R^n$, $f:\R^n \rightarrow \R$ differenzierbar in $x$ und $d$
eine Abstiegsrichtung von $f$ in $x$. Dann gibt es ein $\hat{\sigma} > 0$ mit
\begin{equation}
  f( x + \sigma d) < f(x) \qquad \forall \sigma \in \ ]0, \hat{\sigma}[.
\end{equation}
\end{theorem}

Die meisten Optimierungsverfahren sind iterativ. Sie fangen also mit einem
Anfangspunkt $x^0$ an und versuchen dann weitere Punkte ($x^1, x^2, \ldots , x^k
, \ldots$) zu finden, die besser als die vorherige sind.
Viele iterative Verfahren zur Bestimmung eine lokale Lösung sind häufig
Abstiegsverfahren. In der $k$-ten Iteration bestimmen sie zu einem Punkt~$x^k$
eine Abstiegsrichtung~$d^k$ und eine Schrittweite $\sigma_k$ so, dass für
$x^{k+1} := x^k + \sigma_k d^k$
\begin{equation}
  f(x^{k+1}) < f(x^k)
\end{equation}
gilt.

\subsection{Gradientenverfahren}

Das Gradientenverfahren ist ein einfaches Abstiegsverfahren,
welches die negative Gradienten als Abstiegsrichtungen verwendet.

\begin{algorithm}
\emph{(Gradientenverfahren, vgl. Verfahren 4.2.39 in \cite[S.~98]{alt})}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und ein Abbruchkriterium $\epsilon > 0$.
        Setze $k := 0$.
  \item Ist $\|\nabla f(x^k)\| < \epsilon$ \label{list:stop_criteria_grad_verf}
        $\Rightarrow$ STOP.
  \item Setze $d^k := - \nabla f(x^k)$.
  \item Bestimme $\sigma_k$ so, dass
        \begin{equation}
          f(x^k + \sigma_k d^k) < f(x^k + \sigma d^k)
            \qquad \forall \sigma \geq 0.
        \end{equation}
  \item Setze $x^{k+1} := x^k + \sigma_k d^k$ und $k := k+1$. $\Rightarrow$
        Gehe zu Schritt~\ref{list:stop_criteria_grad_verf}.
\end{enumerate}
\end{algorithm}

Um die Schrittweite $\sigma_k$ zu bestimmen, kann man das Schrittweitenverfahren
von Armijo oder das Schrittweitenverfahren von Wolfe-Powell verwenden.
Wir verweisen auf das Unterkapitel 4.2.7 über Schrittweitenverfahren in
\cite[S.~90ff]{alt}.

\subsection{Newton-Verfahren} \label{sec:newton_verfahren}

Ein bekanntes Verfahren der numerischen Mathematik, um eine nichtlineare
Gleichung zu lösen, ist das Newton-Verfahren.
Man berechnet mit dem Newton-Verfahren eine Nullstelle
von einer gegebenen Abbildung $F:\R^n \rightarrow \R^n$,
d.\,h. eine Lösung $\xopt \in \R^n$ der nichtlinearen Gleichung $F(x) = 0$.
Für unsere unrestringierte Optimierungsprobleme können wir das Newton-Verfahren
verwenden, um die Lösung der nichtlinearen
Gleichung~\eqref{eq:grad_zero},
$\nabla f(x) = 0$, zu finden.
Wir müssen dabei voraussetzen,
dass die Funktion $f$ zweimal differenzierbar sei.

\begin{algorithm}
\emph{(Newton-Verfahren, vgl. Verfahren 4.3.1 in \cite[S.~107]{alt})}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und ein Abbruchkriterium $\epsilon > 0$.
        Setze $k := 0$.
  \item Ist $\|\nabla f(x^k)\| < \epsilon$ \label{list:stop_criteria_newt_verf}
        $\Rightarrow$ STOP.
  \item Berechne die Lösung $d$ des linearen Gleichungssystems
        \begin{equation}
          f''(x^k) d = - \nabla f(x^k).
        \end{equation}
        Setze $d^k := d$.
  \item Setze $x^{k+1} := x^k + d^k$ und $k := k+1$ $\Rightarrow$
        Gehe zu Schritt~\ref{list:stop_criteria_newt_verf}.
\end{enumerate}
\end{algorithm}

Der Punkt $x^{k+1}$ in jedem Iterationschritt ist eigentlich die Lösung des
Minimierungsproblems, welches durch die quadratische Approximation von $f$ in Punkt $x^k$ definiert ist.
In der Umgebung von $x^k$ können wir die Funktion $f$ wie folgt approximieren:
\begin{equation}
  f(x) \approx f(x^k) + \nabla f(x^k)^T (x-x^k)
                 + \frac{1}{2} (x-x^k)^T f''(x^k) (x-x^k).
\end{equation}
Die Ableitung der rechten Seite ist
\begin{equation}
  \nabla f(x^k) + f''(x^k) x - f''(x^k) x^k.
\end{equation}
Setzen wir diese gleich null, dann bekommen wir
\begin{align}
  f''(x^k) (x-x^k) & = - \nabla f(x^k) \\
            x-x^k  & = - [f''(x^k)]^{-1} \nabla f(x^k) \\
            x      & = x^k \underbrace{- [f''(x^k)]^{-1} \nabla f(x^k)}_{d}.
\end{align}
Das ist genau unser Punkt $x^{k+1}$.
D.\,h., wir lösen in jedem Iterationschritt eigentlich das Problem
\begin{equation}
  \min_{x \in \R^n}\ f(x^k) + \nabla f(x^k)^T (x-x^k)
                 + \frac{1}{2} (x-x^k)^T f''(x^k) (x-x^k),
\end{equation}
wobei die Konstante $f(x^k)$ weggelassen werden kann.

Wir werden später sehen, dass das SQP-Verfahren diese Idee auch
gebrauchen wird.

Man kann auch noch eine Schrittweitensteuerung wie bei dem Gradientenverfahren
durchführen. D.\,h., man bestimmt ein $\sigma_k \in \R$ und definiert
$x^{k+1} := x^k + \sigma_k d^k$.
Dann bekommt man ein Abstiegsverfahren,
welches man als das gedämpfte Newton-Verfahren bezeichnet.
Wir verweisen auf das Unterkapitel 4.3.2 über das gedämpfte Newton-Verfahren in
\cite[S.~111ff]{alt}.
% TODO Quasi-Newton-Verfahren bzw. BFGS-Verfahren erwähnen.

% TODO Das Konvergenzverhalten der Verfahren erwähnen?
