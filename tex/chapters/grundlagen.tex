\chapter{Einführung}
%\section{}

Die Mathematik hat schon immer eine enge Beziehung mit Optimierung.
Viele Theorien wurden entwickelt, um eine Optimierungsaufgabe zu lösen.
In der Industrie werden immer wieder gefragt, wie man einen maximalen Gewinn
erzielen kann.
Oft ist auch die Frage wie man etwas minimieren kann,
wie zum Beispiel die gebrauchte Stoffe.
Optimierung spielt immer wieder eine wichtige Rolle,
wenn es um eine Entscheidung geht.

Im Alltag optimiert man auch oft unbewusst.
Wenn man beispielsweise verreisen will, vorbereitet man dann sein Gepäck.
Dabei versucht man so viele Dinge wie möglich in den Koffer
einzupacken, damit man alle Sachen mitbringen kann,
die man nachher braucht.
(Das ist wie das Problem der Dieben mit den Sacken)

Die erste Optimierungsaufgabe? (Euler? Lagrange?)

Zur Optimierung gehören folgende:
\begin{itemize}
\item Zielfunktion
\item Variablen
\item Bedingungen
\end{itemize}

Modellierung (kann zu kompliziert sein und sogar nicht lösbar => vereinfachen)

Optimierungsalgorithmen

Iterative Methode:
\[ f(x^{k+1}) < f(x^k) \]


Optimierung

Aufgabenstellung



Allgemein sieht die Aufgabenstellung bei der nichtlinearen Optimierung so aus:
\[ \min_{x \in \F} f(x) \]

$f:\R^n \rightarrow \R$ ist die sogennante Zielfunktion.
$\F$ ist eine Teilmenge von $\R^n$, die man als Lösungsmenge bezeichnet.
Alle Elemente von $\F$ werden als zulässige Punkte bezeichnet.




Beispiel (mit Bild) 
Ein einfaches Beispiel: $f(x) = (x-1)^2$



Minima?

Globale Optimierung vs. Lokale Optimierung
Restringiert oder Unrestringiert
Konvexität?
Unrestringierte Optimierung?


Approximation der Gradient und Hesse-Matrix?

