\chapter{Einführung}

Die nichtlineare Optimierung ist ein bedeutendes Gebiet der Mathematik.
Sie findet immer wieder Anwendungen in den schwierigen Problemen der Technik und
der Wirtschaft. Es wurden viele Verfahren entwickelt, um nichtlineare
Optimierungsprobleme zu lösen. In dieser Arbeit werden zwei Verfahren, das
halbglatte Newton-Verfahren und das SQP-Verfahren, betrachtet und verglichen.

Das SQP-Verfahren gehört zu den bekanntesten Verfahren der nichtlinearen
Optimierung. Es wurde schon seit den 60er Jahren entwickelt und wurde in vielen
Optimierungsproblemen als Standardwerkzeug angewendet sowie weiterentwickelt.
Das halbglatte Newton-Verfahren ist weniger bekannt als das SQP-Verfahren. Es basiert aber auf
das bekannte Newton-Verfahren.

% TODO tell more about SQP and Semismooth-Newton

\section{Optimierungsprobleme}

\begin{definition}
Allgemein ist die Aufgabenstellung der nichtlinearen Optimierung wie folgt
definiert:
\begin{equation}
  \min_{x \in \F} f(x) \label{P} %TODO set to (P) not (1.1)
\end{equation}
Die Funktion $f:D \subseteq \R^n \rightarrow \R$ ist die sogennante Zielfunktion.
$D$ sei der Definitionsbereich von $f$.
$\F$ sei eine Teilmenge von $D$, die man als Lösungsmenge bezeichnet.
Alle Elemente von $\F$ werden als zulässige Punkte bezeichnet.
$\F$ wird durch Nebenbedingungen definiert.
\end{definition}

Man kann hierbei den Unterschied zwischen der linearen Optimierung und
der nichtlinearen Optimierung erkennen.
Bei der linearen Optimierung muss die Zielfunktion linear sein
(d.h. die Zielfunktion besitzt die Form $f(x) = c^T x$, $c \in \R^n$)
und die Nebenbedingungen sind durch lineare Gleichungssysteme oder
Ungleichungssyteme definiert.
Bei der nichtlinearen Optimierung gibt es dagegen keine Einschränkung,
wie die Zielfunktion und die Nebenbedingungen aussehen sollen.
Für die lineare Optimierung ist ein in der Praxis sehr effizientes Verfahren
bekannt. Aber die Verfahren der nichtlinearen Optimierung sind auch für die
linearen Optimierungsprobleme anwendbar. % TODO: Stimmt das?
Umgekehrt ist es jedoch nicht möglich.

Ein einfaches Beispiel nichtlinearer Optimierung ist das Problem
\[
  \min_{x \in \R} (x-1)^2.
\]

Falls $\F = D$ gilt,
dann bezeichnet man das Optimierungsproblem als unrestringiert.
Es besitzt also keine Nebenbedingungen.
Ansonsten heißt es ein restingiertes Optimierungsproblem.

\begin{definition}
\emph{(Globale und lokale Lösung)}\\
Ein Punkt $\xopt \in \F$ heißt globale Lösung des Problems~(\ref{P}),
wenn
\begin{equation}
  f(\xopt) \leq f(x) \qquad \forall x \in \F
\end{equation}
gilt.
Ein Punkt $\xopt \in \F$ heißt strikte globale Lösung des Problems~(\ref{P}),
wenn
\begin{equation}
  f(\xopt) < f(x) \qquad \forall x \in \F\backslash\{\xopt\}
\end{equation}
gilt.
Ein Punkt $\xopt \in \F$ heißt lokale Lösung des Problems~(\ref{P}), wenn für
eine Umgebung $U(\xopt)$ von $\xopt$
\begin{equation}
  f(\xopt) \leq f(x) \qquad \forall x \in U(\xopt) \cap \F
\end{equation}
gilt.
Ein Punkt $\xopt \in \F$ heißt strikte lokale Lösung des Problems~(\ref{P}),
wenn für eine Umgebung $U(\xopt)$ von $\xopt$
\begin{equation}
  f(\xopt) < f(x) \qquad \forall x \in U(\xopt) \cap \F\backslash\{\xopt\}
\end{equation}
gilt.
Eine Umgebung von $\xopt$ ist einfach eine offene Menge, die $\xopt$ beinhaltet.
\end{definition}

Wegen dieser Definitionen kommt die Unterscheidung zwischen der globalen
und der lokalen Optimierung. Globale Optimierung versucht, globale Lösungen
zu finden. Lokale Optimierung versucht dagegen, lokale Lösungen zu finden.
Viele Verfahren finden lokale Lösungen, die jedoch nicht unbedingt
globale Lösungen sind.

% TODO?: Konvexität

Wir betrachten nun das unrestringierte Optimierungsproblem
\begin{equation}
  \min_{x \in \R^n} f(x). \label{PU} % TODO: change to (PU) not (1.6)
\end{equation}

Wir nehmen hier an, dass der Definitionsbereich $D$ gleich $\R^n$ sei.

\begin{theorem}
\emph{(Notwendige Bedingung erster Ordnung)}\\
Seien $\xopt$ eine lokale Lösung des Problems~(\ref{PU}) und $f$ einmal stetig
differenzierbar in einer Umgebung von $\xopt$, dann gilt
\begin{equation}
  \nabla f(\xopt) = 0 \label{Gradient ist null}
\end{equation}
\end{theorem}

\begin{definition}
\emph{(Stationärer Punkt)}\\
$f$ sei in $\xopt$ differenzierbar. $\xopt$ heißt ein stationärer Punkt von $f$,
wenn $\xopt$ die notwendige Bedingung~(\ref{Gradient ist null}) erfüllt.
\end{definition}

\begin{theorem}
\emph{(Notwendige Bedingung zweiter Ordnung)}\\
Seien $\xopt$ eine lokale Lösung des Problems~(\ref{PU}) und $f$ zweimal stetig
differenzierbar in einer Umgebung von $\xopt$, dann gilt~(\ref{Gradient ist
null}) und
\begin{equation}
  x^T f''(\xopt) x \geq 0 \qquad \forall x \in \R^n,
\end{equation}
$f''(\xopt)$ ist also positiv semidefinit.
\end{theorem}

\begin{theorem}
\emph{(Hinreichende Bedingung zweiter Ordnung)}\\
Sei $f$ zweimal stetig differenzierbar in einer Umgebung von $\xopt$.
Die notwendige Bedingung~(\ref{Gradient ist null}) sei erfüllt und $f''(\xopt)$
sei positiv definit, d.h.
\begin{equation}
  x^T f''(\xopt) x > 0 \qquad \forall x \in \R^n.
\end{equation}
Dann ist $\xopt$ eine strikte Lösung des Problems~(\ref{PU}).
\end{theorem}

% TODO: Iterative Methode: \[ f(x^{k+1}) < f(x^k) \]

% TODO: Unrestringerte Optimierungsprobleme: Theorie und Verfahren

% TODO: Approximation der Gradient und Hesse-Matrix?
